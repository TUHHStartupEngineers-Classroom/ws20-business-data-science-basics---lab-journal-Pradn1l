---
title: "Journal (reproducible report)"
author: "Pradnil S Kamble"
date: "2020-11-28"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**Welcome to Pradnil's Site** 

*Checklist of completed tasks*

Assignment 1: Challenge 1 *Completed*

Assignment 2: Challenge 2 *Completed*

Assignment 3: Challenge 3 *incomplete*

Assignment 4: Challenge 4.1 and Challenge 4.2 *Completed*

# Assingment 1
Last compiled: `r Sys.Date()`

Goal:

1) Analyze the sales by location (state) with a bar plot. 
2) Since state and city are multiple features (variables), they should be split. 
3) Which state has the highes revenue? Replace your bike_orderlines_wrangled_tbl object with the newly wrangled object (with the columns state and city).
4) Analyze the sales by location and year (facet_wrap). Because there are 12 states with bike stores, you should get 12 plots.

```{r}
# Data Science at TUHH ------------------------------------------------------
# SALES ANALYSIS ----
# P1x

#libraries ----
library(tidyverse)
library(readxl)
library(lubridate)
library("writexl")

# Importing Files ----
bikes_tbl      <- read_excel("bikes.xlsx")
orderlines_tbl <- read_excel("orderlines.xlsx")
bikeshops_tbl <- read_excel("bikeshops.xlsx")

# Examining Data ----
View(orderlines_tbl)
View(bikeshops_tbl)
View(bikes_tbl)

# Joining Data ----
bike_orderlines_joined_tbl <- orderlines_tbl %>% left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>% left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))

# Wrangling Data ----
bike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>% separate(col    = location, into   = c("city", "State"), sep    = ",") %>% 
mutate(total.price = price * quantity) %>% rename(bikeshop = name) %>% set_names(names(.) %>% str_replace_all("\\.", "_"))

# Business Insights ----

# Sales by State ----

# 1 - Manipulate
sales_by_state_tbl <- bike_orderlines_wrangled_tbl %>% select(State, total_price) %>% group_by(State) %>% summarize(sales = sum(total_price)) %>%
mutate(sales_text = scales::dollar(sales, big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €"))
View(sales_by_state_tbl)

sales_by_city_tbl <- bike_orderlines_wrangled_tbl %>% select(city, total_price) %>% group_by(city) %>% summarize(sales = sum(total_price)) %>%
mutate(sales_text = scales::dollar(sales, big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €"))
View(sales_by_city_tbl)

# Visualize


sales_by_state_tbl %>%
ggplot(aes(x = State, y = sales)) +
geom_col(fill = "#2DC6D6") + 
geom_label(aes(label = sales_text)) +
geom_smooth(method = "lm", se = FALSE) + 
scale_y_continuous(labels = scales::dollar_format(big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €")) +
labs(title    = "Revenue by state", subtitle = "Upward Trend", x = "", y = "Revenue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))


sales_by_city_tbl %>%
ggplot(aes(x = city, y = sales)) +
geom_col(fill = "#2DC6D6") + 
geom_label(aes(label = sales_text)) +
geom_smooth(method = "lm", se = FALSE) + 
scale_y_continuous(labels = scales::dollar_format(big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €")) +
labs(title    = "Revenue by city", subtitle = "Upward Trend", x = "", y = "Revenue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Sales as per Year and location ----

# Manipulate
sales_by_location_year_tbl <- bike_orderlines_wrangled_tbl %>% select(State, order_date, total_price) %>%  mutate(year = year(order_date)) %>%
group_by(State ,year) %>% summarize(sales = sum(total_price)) %>% mutate(sales_text = scales::dollar(sales, big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €"))
View(sales_by_location_year_tbl)

# Visualize
sales_by_location_year_tbl %>%
ggplot(aes(x = year, y = sales)) +
geom_col(fill = "#2DC6D6") + 
geom_label(aes(label = sales_text)) +
geom_smooth(method = "lm", se = FALSE) + 
scale_y_continuous(labels = scales::dollar_format(big.mark = ".", decimal.mark = ",", prefix = "", suffix = " €")) +
labs(title    = "Revenue by state and year", subtitle = "Upward Trend", x = "", y = "Revenue")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
facet_wrap(vars(State))
```



# Assignment 2

GOal:

1) Get some data via an API.
2) Scrape one of the competitor websites of canyon (https://www.radon-bikes.de) and create a small database.
3)The database should contain the model names and prices for at least one category. Use the selectorgadget to get a good understanding of the website structure.

```{r}
library(tidyverse) 
library(rvest)    
library(xopen)    
library(jsonlite) 
library(glue)     
library(stringi) 

url_home <- "https://www.radon-bikes.de/"
xopen(url_home) 

html_home <- read_html(url_home)
list_of_product_types <- html_home%>%
  html_nodes(css = ".megamenu__item > a")%>%
  html_text()


list_of_products_url <- html_home %>%
  html_nodes(".megamenu__item > a") %>%
  html_attr("href") %>%
  enframe(name = NULL, value = "url") %>%
  mutate(url = str_glue("https://www.radon-bikes.de{url}"))


bike_category_url <- list_of_products_url$url[1]

xopen(bike_category_url)


html_bike_category  <- read_html(bike_category_url)
temp_url <- html_bike_category%>%
  html_node(".a-button--hollow-secondary")%>%
  html_attr("href")%>%
  enframe(name = NULL, value = "url") %>%
  mutate(url = str_glue("https://www.radon-bikes.de{url}"))

temp_url <- temp_url$url[1]
xopen(temp_url)

bike_category_grid_html <- read_html(temp_url)

list_of_product_names <- bike_category_grid_html%>%
  html_nodes(css=".m-bikegrid__info > a > div > h4")%>%
  html_text%>%
  stringr::str_replace_all(pattern = "\n","")%>%
  stringr::str_replace_all(pattern = "  ","")%>%
  enframe(name = NULL, value = "NAME")



list_of_product_prices <- bike_category_grid_html%>%
  html_nodes(css=".m-bikegrid__price--active")%>%
  html_text()%>%
  stringr::str_extract(pattern = "[0-9€]+")%>%
  stringr::str_replace(pattern = "€","")%>%
  as.numeric()%>%
  enframe(name = NULL, value = "PRICE")

list_of_product_prices = na.omit(list_of_product_prices)
```

# Assignment 3

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```



# Assignment 4

## challenge 1

Goal: Map the time course of the cumulative Covid-19 cases! Your plot should look like this:

```{r}
library(tidyverse)
library(data.table)
library(ggplot2)
library(ggrepel)
url <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"
covid_data_tbl <- fread(url)

class(covid_data_tbl)
colnames(covid_data_tbl)
str(covid_data_tbl)

#check: unique country
unique(covid_data_tbl$countriesAndTerritories)

#get: month name column
covid_data_tbl$month_name<-months(as.Date(covid_data_tbl$dateRep))

##rolling up data to month year country Level
covid_mon_yr_country_lvl <- covid_data_tbl %>% 
  dplyr::group_by(month,month_name,year,countriesAndTerritories,geoId,countryterritoryCode,continentExp) %>% 
  dplyr::summarise(cases = sum(cases, na.rm = T)) %>% 
  dplyr::ungroup()

##generating Cummulative Cases column
covid_mon_yr_country_lvl <- covid_mon_yr_country_lvl %>% 
  dplyr::arrange(countriesAndTerritories,year,month) %>% 
  dplyr::group_by(countriesAndTerritories) %>% 
  dplyr::mutate(cumulative_cases = cumsum(cases)) %>% 
  dplyr::ungroup()

##filtering  for the year = 2020
covid_mon_yr_country_lvl_fil<- covid_mon_yr_country_lvl %>% 
  dplyr::filter(countriesAndTerritories %in% c("Germany","Spain","France","United_Kingdom","United_States_of_America")& year == 2020) %>%
  dplyr::rename('Continent_Country' = countriesAndTerritories)

#Graph ggplot
covid_mon_yr_country_lvl_fil %>% 
  mutate(label = if_else(month_name == "December",as.character(cumulative_cases),NA_character_)) %>% 
  ggplot(aes(x=month,y =cumulative_cases))+
  geom_line(aes(color = Continent_Country))+
  scale_colour_brewer(palette = "Set3")+
  scale_x_continuous(breaks=covid_mon_yr_country_lvl_fil$month,labels = covid_mon_yr_country_lvl_fil$month_name)+
  scale_y_continuous(labels = scales::dollar_format(scale = 1/1e6,
                                                    prefix = "",
                                                    suffix = "M"))+
  labs(title = "COVID-19 confirmed cases worldwide",
       subtitle =  "As of 12/5/2020,USA has the highest cases.",
       x = "Year 2020",
       y= "Cumulative Cases"
  )+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle=45,hjust = 1))+
  geom_label_repel(aes(label=label),
                   nudge_x = 1,na.rm = TRUE)
```



## challenge 2 

Goal: Visualize the distribution of the mortality rate (deaths / population) with geom_map(). The necessary longitudinal and lateral data can be accessed with this function:

```{r}
library(tidyverse)
library(data.table)
library(ggplot2)
library(ggrepel)
library(maps)
library(ggthemes)
library(mapproj)


url <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"
covid_data_tbl <- fread(url)

world <- map_data("world")
colnames((world))

covid_data_tbl$countriesAndTerritories <- str_replace_all(covid_data_tbl$countriesAndTerritories,"_"," ")
world_data<- covid_data_tbl %>% 
  dplyr::mutate(countriesAndTerritories = case_when(
    countriesAndTerritories == "United Kingdom" ~ "UK",
    countriesAndTerritories == "United States of America" ~ "USA",
    countriesAndTerritories == "Czechia" ~ "Czech Republic",
    TRUE ~ countriesAndTerritories
  ))

options(scipen = 999)

country_mortality_rate<- world_data %>% 
  dplyr::group_by(countriesAndTerritories) %>% 
  dplyr::summarise(deaths = sum(deaths, na.rm = T),
                   popData2019 = nth(popData2019,1)) %>% 
  dplyr::mutate(mortality_rate = round((deaths/popData2019)*100,3))

plot_data <- country_mortality_rate %>%  
  dplyr::right_join(world,by=c("countriesAndTerritories"="region"))

plot_data %>% ggplot()+
  geom_map(map = world,aes(map_id = countriesAndTerritories,fill=mortality_rate),color = "#7f7f7f",size=0.25)+
  scale_fill_gradient(low="#FF3333",high = "#330000",name="Mortality Rate")+
  expand_limits(x= world$long,y=world$lat)+
  labs(x="",y="",title="Confirmed COVID-19 deaths relative to the size of population")
```

**Thank you**
